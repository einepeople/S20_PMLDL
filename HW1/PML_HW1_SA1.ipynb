{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PML_HW1_SA1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljpvkPBV36GT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGr0Z_RpEx0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data, target = load_iris(True)\n",
        "scl = StandardScaler()\n",
        "data = scl.fit_transform(data)\n",
        "xtr, xts, ytr, yts = tts(data, target, test_size = 0.5)\n",
        "ytr, yts = torch.tensor(ytr).long(), torch.tensor(yts).long()\n",
        "xtr, xts = torch.tensor(xtr).float(), torch.tensor(xts).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6k_AVxUEzsd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.net = torch.nn.Sequential(\n",
        "        torch.nn.Linear(4,3),\n",
        "        torch.nn.SELU(),\n",
        "        torch.nn.Linear(3,3),\n",
        "        torch.nn.Softmax(dim = 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtSt0QqsGW-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimAnnealing(torch.optim.Optimizer):\n",
        "  def __init__(self, params, T = 2.0, p_variance = 0.05, annealing_rate = 0.99, anneal_every=5):\n",
        "    if T <= 0.0:\n",
        "      raise RuntimeError('Initial T must be positive!')\n",
        "    if not ( 0.0 < annealing_rate < 1.0):\n",
        "      raise RuntimeError('Annealing rate must be between 0 and 1 exclusively!')\n",
        "    defaults = dict(T = T, anr = annealing_rate)\n",
        "    self.T = T\n",
        "    self.anr = annealing_rate\n",
        "    self.pvar = p_variance\n",
        "    self.ane = anneal_every\n",
        "    self.nstep = 0\n",
        "    super(SimAnnealing, self).__init__(params, defaults)\n",
        "\n",
        "  def get_T(self):\n",
        "    return self.T\n",
        "\n",
        "  def step(self, closure = None):\n",
        "\n",
        "    def p_star(num, T):\n",
        "      return num.div_(-T).exp_()\n",
        "\n",
        "    def fmt(unit):\n",
        "      return round(unit.item(),5) \n",
        "    if not closure:\n",
        "      raise RuntimeError('SA requires closure for computing acceptance ratio!')\n",
        "    loss = p_star(closure(), self.T)\n",
        "    self.nstep += 1\n",
        "\n",
        "    for group in self.param_groups:\n",
        "      back_weights = [-1]*len(group['params'])\n",
        "      for i,p in enumerate(group['params']):\n",
        "        back_weights[i] = p.data\n",
        "        p.data = torch.distributions.Normal(p.data, self.pvar).sample()\n",
        "      new_loss = p_star(closure(), self.T)\n",
        "      u = torch.distributions.Uniform(0,1).sample()\n",
        "      if u.item() > new_loss.item()/loss.item():\n",
        "        for i,p in enumerate(group['params']):\n",
        "          p.data = back_weights[i]\n",
        "    if not (self.nstep % self.ane):\n",
        "      self.T *= self.anr\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPyT0xKzHoEG",
        "colab_type": "code",
        "outputId": "2d30f645-5025-43ef-e865-2982fbce74fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == torch.nn.Linear:\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "SEED = 12345678\n",
        "torch.manual_seed(SEED)\n",
        "nn = Net()\n",
        "nn.apply(init_weights)\n",
        "opt = SimAnnealing(nn.parameters())\n",
        "lossfn = torch.nn.CrossEntropyLoss()\n",
        "i = -1\n",
        "max_acc = 0.0\n",
        "max_wieghts_dict = None\n",
        "\n",
        "while opt.get_T() > 0.003:\n",
        "  i+=1\n",
        "  def closure():\n",
        "        opt.zero_grad()\n",
        "        pred = nn(xtr)\n",
        "        loss = lossfn(pred, ytr)\n",
        "        loss.backward()\n",
        "        return loss\n",
        "  try:\n",
        "    loss = opt.step(closure)  \n",
        "  except ZeroDivisionError:\n",
        "    print('Rounded loss zeroed. Stopping!')\n",
        "    print(f'Best accuracy = {round(max_acc.item(),4)}')\n",
        "    break\n",
        " \n",
        "  y_pred = nn(xts)\n",
        "  correct = (torch.argmax(y_pred,dim=1) == yts).float().sum()\n",
        "  acc = correct/len(yts)\n",
        "  if acc > max_acc:\n",
        "    max_acc = acc\n",
        "    max_wieghts_dict = nn.state_dict()\n",
        "  if not i % 50 or acc > 0.9:\n",
        "    print(f\"Epoch#{i}: Train energy level = {loss.item()}, test accuracy = {round(acc.item(),4)}\")\n",
        "  if acc > 0.9:\n",
        "    break"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch#0: Train energy level = 0.584721028804779, test accuracy = 0.4667\n",
            "Epoch#50: Train energy level = 0.6008089184761047, test accuracy = 0.7333\n",
            "Epoch#100: Train energy level = 0.5920114517211914, test accuracy = 0.76\n",
            "Epoch#150: Train energy level = 0.5689440965652466, test accuracy = 0.72\n",
            "Epoch#200: Train energy level = 0.4923363924026489, test accuracy = 0.68\n",
            "Epoch#250: Train energy level = 0.4139770269393921, test accuracy = 0.44\n",
            "Epoch#300: Train energy level = 0.4578160345554352, test accuracy = 0.7467\n",
            "Epoch#350: Train energy level = 0.4415571093559265, test accuracy = 0.7067\n",
            "Epoch#400: Train energy level = 0.3933446705341339, test accuracy = 0.7333\n",
            "Epoch#450: Train energy level = 0.35685524344444275, test accuracy = 0.72\n",
            "Epoch#500: Train energy level = 0.27824288606643677, test accuracy = 0.52\n",
            "Epoch#550: Train energy level = 0.2541567087173462, test accuracy = 0.64\n",
            "Epoch#600: Train energy level = 0.1995590478181839, test accuracy = 0.6133\n",
            "Epoch#650: Train energy level = 0.21134009957313538, test accuracy = 0.72\n",
            "Epoch#700: Train energy level = 0.14489901065826416, test accuracy = 0.6133\n",
            "Epoch#750: Train energy level = 0.16830292344093323, test accuracy = 0.76\n",
            "Epoch#800: Train energy level = 0.12821577489376068, test accuracy = 0.7067\n",
            "Epoch#850: Train energy level = 0.10127682238817215, test accuracy = 0.7067\n",
            "Epoch#900: Train energy level = 0.038453444838523865, test accuracy = 0.4133\n",
            "Epoch#950: Train energy level = 0.0322374552488327, test accuracy = 0.56\n",
            "Epoch#1000: Train energy level = 0.016122112050652504, test accuracy = 0.44\n",
            "Epoch#1050: Train energy level = 0.007296680472791195, test accuracy = 0.4\n",
            "Epoch#1100: Train energy level = 0.014968289993703365, test accuracy = 0.68\n",
            "Epoch#1150: Train energy level = 0.018297508358955383, test accuracy = 0.7467\n",
            "Epoch#1200: Train energy level = 0.007801082916557789, test accuracy = 0.6933\n",
            "Epoch#1250: Train energy level = 0.0013700658455491066, test accuracy = 0.5867\n",
            "Epoch#1300: Train energy level = 0.0005326716927811503, test accuracy = 0.48\n",
            "Epoch#1350: Train energy level = 8.235994755523279e-05, test accuracy = 0.4\n",
            "Epoch#1400: Train energy level = 2.3785014491295442e-05, test accuracy = 0.3867\n",
            "Epoch#1450: Train energy level = 7.461794666596688e-06, test accuracy = 0.32\n",
            "Epoch#1500: Train energy level = 1.684720359662606e-06, test accuracy = 0.3333\n",
            "Epoch#1550: Train energy level = 6.69088819904573e-07, test accuracy = 0.3867\n",
            "Epoch#1600: Train energy level = 1.446879025479575e-07, test accuracy = 0.36\n",
            "Epoch#1650: Train energy level = 2.0857651605865613e-08, test accuracy = 0.3733\n",
            "Epoch#1700: Train energy level = 1.0074026945972037e-08, test accuracy = 0.4267\n",
            "Epoch#1750: Train energy level = 3.5303116874274565e-07, test accuracy = 0.6533\n",
            "Epoch#1800: Train energy level = 3.044243257477319e-08, test accuracy = 0.5867\n",
            "Epoch#1850: Train energy level = 4.141375242738832e-08, test accuracy = 0.72\n",
            "Epoch#1900: Train energy level = 2.5475697107424367e-09, test accuracy = 0.6667\n",
            "Epoch#1950: Train energy level = 5.123957369512766e-10, test accuracy = 0.6933\n",
            "Epoch#2000: Train energy level = 4.373158224435514e-10, test accuracy = 0.7867\n",
            "Epoch#2050: Train energy level = 4.245955323445294e-11, test accuracy = 0.72\n",
            "Epoch#2100: Train energy level = 2.9363718487968038e-12, test accuracy = 0.8267\n",
            "Epoch#2150: Train energy level = 2.4463419571324474e-12, test accuracy = 0.84\n",
            "Epoch#2200: Train energy level = 3.6079534406754585e-14, test accuracy = 0.76\n",
            "Epoch#2250: Train energy level = 9.146669399057801e-16, test accuracy = 0.8133\n",
            "Epoch#2300: Train energy level = 9.078112008144916e-18, test accuracy = 0.8133\n",
            "Epoch#2350: Train energy level = 3.7035709117597043e-19, test accuracy = 0.8133\n",
            "Epoch#2400: Train energy level = 4.56163854532069e-21, test accuracy = 0.8133\n",
            "Epoch#2450: Train energy level = 2.7717356812416674e-23, test accuracy = 0.8267\n",
            "Epoch#2500: Train energy level = 2.866204565237336e-25, test accuracy = 0.84\n",
            "Epoch#2550: Train energy level = 5.530269798191546e-28, test accuracy = 0.8533\n",
            "Epoch#2600: Train energy level = 7.685304012851221e-31, test accuracy = 0.8267\n",
            "Epoch#2650: Train energy level = 5.23981474160331e-34, test accuracy = 0.76\n",
            "Epoch#2700: Train energy level = 1.049984083112291e-37, test accuracy = 0.8267\n",
            "Epoch#2750: Train energy level = 3.9505406306245243e-41, test accuracy = 0.8267\n",
            "Epoch#2800: Train energy level = 1.401298464324817e-45, test accuracy = 0.8\n",
            "Rounded loss zeroed. Stopping!\n",
            "Best accuracy = 0.8533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0HXU1FhK3Ub",
        "colab_type": "code",
        "outputId": "5124f98a-fcac-46b0-afbf-a1050189e965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "torch.manual_seed(SEED)\n",
        "nn = Net()\n",
        "nn.apply(init_weights)\n",
        "opt = torch.optim.Adadelta(nn.parameters())\n",
        "lossfn = torch.nn.CrossEntropyLoss()\n",
        "i = 0\n",
        "max_acc = 0.0\n",
        "max_wieghts_dict = None\n",
        "max_iter = 2000\n",
        "\n",
        "while i <= max_iter:\n",
        "  i+=1\n",
        "  def closure():\n",
        "        opt.zero_grad()\n",
        "        pred = nn(xtr)\n",
        "        loss = lossfn(pred, ytr)\n",
        "        loss.backward()\n",
        "        return loss\n",
        "  loss = opt.step(closure)  \n",
        "  y_pred = nn(xts)\n",
        "  correct = (torch.argmax(y_pred,dim=1) == yts).float().sum()\n",
        "  acc = correct/len(yts)\n",
        "  if acc > max_acc:\n",
        "    max_acc = acc\n",
        "    max_wieghts_dict = nn.state_dict()\n",
        "  if not i % 50 or acc > 0.9:\n",
        "    print(f\"Epoch#{i}: Train loss = {loss.item()}, test accuracy = {round(acc.item(),4)}\")\n",
        "  if acc > 0.9:\n",
        "    break"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch#50: Train loss = 0.8260712623596191, test accuracy = 0.7733\n",
            "Epoch#100: Train loss = 0.7506687641143799, test accuracy = 0.84\n",
            "Epoch#136: Train loss = 0.710701584815979, test accuracy = 0.9067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZwt94zoPT1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsXlaRuUVPqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z19GtkIvWz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}